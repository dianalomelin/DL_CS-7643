{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MABe Task 3: Learning New Behavior Baseline",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dianalomelin/DL_CS-7643/blob/main/MABe_Task_3_Learning_New_Behavior_Baseline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LNzVqbnxvTRS"
      },
      "source": [
        "![AIcrowd-Logo](https://images.aicrowd.com/raw_images/challenges/banner_file/757/b658c16b21044c7d2a9a.jpg)\n",
        "\n",
        "\n",
        "\n",
        "<p align=\"center\"> Join the communty! <br><a href=\"https://discord.gg/GTckBMx\"><img src=\"https://img.shields.io/discord/657211973435392011?style=for-the-badge\" alt=\"chat on Discord\"></a>\n",
        "</p>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f4w4yZOfV5le"
      },
      "source": [
        "<h1> <center>\n",
        "ğŸ€ğŸ€ğŸ€ğŸ€ğŸ€ğŸ€ğŸ€ğŸ€ğŸ€ğŸ€ğŸ€ğŸğŸğŸğŸğŸğŸğŸğŸğŸğŸ<br>\n",
        "ğŸ€ MABe Learning New Behaviors: Baseline ğŸ<br>\n",
        "ğŸ€ğŸ€ğŸ€ğŸ€ğŸ€ğŸ€ğŸ€ğŸ€ğŸ€ğŸ€ğŸ€ğŸğŸğŸğŸğŸğŸğŸğŸğŸğŸ\n",
        "</center>\n",
        "</h1>\n",
        "\n",
        "<p align=\"center\"><img src=\"https://images.aicrowd.com/uploads/ckeditor/pictures/329/content_task3_structure.png\">\n",
        "<img src=\"https://images.aicrowd.com/uploads/ckeditor/pictures/330/content_task0_structure.png\">\n",
        "\n",
        "</p>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ad-nu4cbF_fI"
      },
      "source": [
        "# How to use this notebook ğŸ“\n",
        "\n",
        "1. **Copy the notebook**. This is a shared template and any edits you make here will not be saved. _You should copy it into your own drive folder._ For this, click the \"File\" menu (top-left), then \"Save a Copy in Drive\". You can edit your copy however you like.\n",
        "2. **Link it to your AIcrowd account**. In order to submit your predictions to AIcrowd, you need to provide your account's API key.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fOsJQCoRvTRY"
      },
      "source": [
        "# Setup AIcrowd Utilities ğŸ› "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jCKS_X_KvTRY"
      },
      "source": [
        "!pip install -U aicrowd-cli"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LuQQrNvkID8J"
      },
      "source": [
        "# Install packages ğŸ—ƒ\n",
        "\n",
        "Please add all pacakages installations in this section"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OPsQS64kIFIz"
      },
      "source": [
        "!pip install tensorflow-addons"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jsaWsU8dILfN"
      },
      "source": [
        "# Import necessary modules and packages ğŸ“š\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G4CVVoCjIN95"
      },
      "source": [
        "import numpy as np\n",
        "import os\n",
        "\n",
        "from tensorflow import keras\n",
        "import tensorflow as tf\n",
        "from keras.models import Sequential\n",
        "import keras.layers as layers\n",
        "import tensorflow_addons as tfa\n",
        "\n",
        "import sklearn\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from copy import deepcopy\n",
        "from tqdm.auto  import tqdm\n",
        "import gc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KwykJ9kzvTRZ"
      },
      "source": [
        "# Download the dataset ğŸ“²\n",
        "\n",
        "Please get your API key from https://www.aicrowd.com/participants/me\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ekJZdhqrvTRa"
      },
      "source": [
        "API_KEY = \"8d3a0fe18526544898ce7e12c244d400\"\n",
        "!aicrowd login --api-key $API_KEY"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FwZgcLsNDej_"
      },
      "source": [
        "!aicrowd  dataset download --challenge mabe-task-3-learning-new-behavior"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Md4em-KzIofe"
      },
      "source": [
        "Extract the downloaded dataset to `data` directory\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jXNMUq-UVc8E"
      },
      "source": [
        "!rm -rf data\n",
        "!mkdir data\n",
        " \n",
        "!mv train.npy data/train.npy\n",
        "!mv test-release.npy data/test.npy\n",
        "!mv sample-submission.npy data/sample_submission.npy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7MLxouZUvTRa"
      },
      "source": [
        "# Load Data\n",
        "The dataset files are python dictionaries, [this](https://colab.research.google.com/drive/1ddCX-TAdEcsUaGf09f5Glgr_G57FMK_O#scrollTo=JPsfxdl2GMcM&line=18&uniqifier=1) is a descirption of how the data is organized.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RopVoFl1vTRb"
      },
      "source": [
        "train = np.load('data/train.npy',allow_pickle=True).item()\n",
        "test = np.load('data/test.npy',allow_pickle=True).item()\n",
        "sample_submission = np.load('data/sample_submission.npy',allow_pickle=True).item()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YFcS9p3haBkK"
      },
      "source": [
        "## Dataset Specifications ğŸ’¾\n",
        "\n",
        "-   **`train.npy`** - Training set for the task, which follows the following schema:\n",
        "\n",
        "<p align=\"left\" style=\"padding: 30px\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<img width=\"600px\" src=\"https://i.imgur.com/GddvoT2.png\">\n",
        "</p>\n",
        "\n",
        "\n",
        "-   **`test-release.npy`** - Test set for the task, which follows the following schema :\n",
        "\n",
        "<p align=\"left\" style=\"padding: 30px\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<img width=\"600px\" src=\"https://i.imgur.com/vfa8Y4V.png\">\n",
        "</p>\n",
        "\n",
        "-   **`sample_submission.npy`** - Template for a sample submission which follows the following schema\n",
        "\n",
        "```json\n",
        "{\n",
        "    \"<sequence_id-1>\" : [0, 0, 1, 2, ...],\n",
        "    \"<sequence_id-2>\" : [0, 1, 2, 0, ...]\n",
        "}\n",
        "```\n",
        "\n",
        "Each key in the dictionary here refers to the unique sequence id obtained for the sequences in the test set.\n",
        "The value for each of the keys is expected to hold a list of corresponing annotations. The annotations are represented by the index of the corresponding annotation words in the vocabular provided in the test set."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JUkb35tcf4bn"
      },
      "source": [
        "## How does the data look like? ğŸ”\n",
        "\n",
        "Task 3 has 7 sets of new behaviors, all binary classifications\n",
        "The test set is combined for all behaviors, you need to output behavior labels for all sequences in test set.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CYIC5DW_oRPb"
      },
      "source": [
        "print(\"Dataset keys - \", train.keys())\n",
        "print()\n",
        "for behavior in train:\n",
        "  print(\"Vocabulary - \", train[behavior]['vocabulary'])\n",
        "  print(\"Number of train Sequences - \", len(train[behavior]['sequences']))\n",
        "  print()\n",
        "print(\"Number of test Sequences - \", len(test['sequences']))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CgesSq6SEHIV"
      },
      "source": [
        "## Submission Format\n",
        "Test set 458 sequences, so you need to make 7*458 sets of predictions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CGGGsEhNELGF"
      },
      "source": [
        "print(\"Sample Submission keys - \", sample_submission.keys())\n",
        "for beh in sample_submission:\n",
        "  print(f\"Test videos for {beh}\", len(sample_submission[beh]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "luUly4Y1i4L-"
      },
      "source": [
        "### Sample overview"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hh9dj4wG3rV0"
      },
      "source": [
        "behavior_0 = train['behavior-0']\n",
        "sequence_names = list(behavior_0[\"sequences\"].keys())\n",
        "sequence_key = sequence_names[0]\n",
        "single_sequence = behavior_0[\"sequences\"][sequence_key]\n",
        "print(\"Sequence name - \", sequence_key)\n",
        "print(\"Single Sequence keys \", single_sequence.keys())\n",
        "print(f\"Number of Frames in {sequence_key} - \", len(single_sequence['annotations']))\n",
        "print(f\"Keypoints data shape of {sequence_key} - \", single_sequence['keypoints'].shape)\n",
        "print(f\"annotator_id of {sequence_key} - \", single_sequence['annotator_id'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_WGK1pjV81oc"
      },
      "source": [
        "# Helper function for visualization ğŸ’\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Don't forget to run the cell ğŸ˜‰"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kf7CXiH85odZ"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import animation\n",
        "from matplotlib import colors\n",
        "from matplotlib import rc\n",
        " \n",
        "rc('animation', html='jshtml')\n",
        " \n",
        "# Note: Image processing may be slow if too many frames are animated.                \n",
        " \n",
        "#Plotting constants\n",
        "FRAME_WIDTH_TOP = 1024\n",
        "FRAME_HEIGHT_TOP = 570\n",
        " \n",
        "RESIDENT_COLOR = 'lawngreen'\n",
        "INTRUDER_COLOR = 'skyblue'\n",
        " \n",
        "PLOT_MOUSE_START_END = [(0, 1), (0, 2), (1, 3), (2, 3), (3, 4),\n",
        "                        (3, 5), (4, 6), (5, 6), (1, 2)]\n",
        " \n",
        "class_to_color = {'other': 'white', 'behavior-0' : 'red'}\n",
        " \n",
        "class_to_number = {s: i for i, s in enumerate(behavior_0['vocabulary'])}\n",
        " \n",
        "number_to_class = {i: s for i, s in enumerate(behavior_0['vocabulary'])}\n",
        " \n",
        "def num_to_text(anno_list):\n",
        "  return np.vectorize(number_to_class.get)(anno_list)\n",
        " \n",
        "def set_figax():\n",
        "    fig = plt.figure(figsize=(6, 4))\n",
        " \n",
        "    img = np.zeros((FRAME_HEIGHT_TOP, FRAME_WIDTH_TOP, 3))\n",
        " \n",
        "    ax = fig.add_subplot(111)\n",
        "    ax.imshow(img)\n",
        " \n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        " \n",
        "    return fig, ax\n",
        " \n",
        "def plot_mouse(ax, pose, color):\n",
        "    # Draw each keypoint\n",
        "    for j in range(7):\n",
        "        ax.plot(pose[j, 0], pose[j, 1], 'o', color=color, markersize=5)\n",
        " \n",
        "    # Draw a line for each point pair to form the shape of the mouse\n",
        " \n",
        "    for pair in PLOT_MOUSE_START_END:\n",
        "        line_to_plot = pose[pair, :]\n",
        "        ax.plot(line_to_plot[:, 0], line_to_plot[\n",
        "                :, 1], color=color, linewidth=1)\n",
        " \n",
        "def animate_pose_sequence(video_name, keypoint_sequence, start_frame = 0, stop_frame = 100, \n",
        "                          annotation_sequence = None):\n",
        "    # Returns the animation of the keypoint sequence between start frame\n",
        "    # and stop frame. Optionally can display annotations.\n",
        "    seq = keypoint_sequence.transpose((0,1,3,2))\n",
        " \n",
        "    image_list = []\n",
        "    \n",
        "    counter = 0\n",
        "    for j in range(start_frame, stop_frame):\n",
        "        if counter%20 == 0:\n",
        "          print(\"Processing frame \", j)\n",
        "        fig, ax = set_figax()\n",
        "        plot_mouse(ax, seq[j, 0, :, :], color=RESIDENT_COLOR)\n",
        "        plot_mouse(ax, seq[j, 1, :, :], color=INTRUDER_COLOR)\n",
        "        \n",
        "        if annotation_sequence is not None:\n",
        "          annot = annotation_sequence[j]\n",
        "          annot = number_to_class[annot]\n",
        "          plt.text(50, -20, annot, fontsize = 16, \n",
        "                   bbox=dict(facecolor=class_to_color[annot], alpha=0.5))\n",
        " \n",
        "        ax.set_title(\n",
        "            video_name + '\\n frame {:03d}.png'.format(j))\n",
        " \n",
        "        ax.axis('off')\n",
        "        fig.tight_layout(pad=0)\n",
        "        ax.margins(0)\n",
        " \n",
        "        fig.canvas.draw()\n",
        "        image_from_plot = np.frombuffer(fig.canvas.tostring_rgb(),\n",
        "                                        dtype=np.uint8)\n",
        "        image_from_plot = image_from_plot.reshape(\n",
        "            fig.canvas.get_width_height()[::-1] + (3,)) \n",
        " \n",
        "        image_list.append(image_from_plot)\n",
        " \n",
        "        plt.close()\n",
        "        counter = counter + 1\n",
        " \n",
        "    # Plot animation.\n",
        "    fig = plt.figure()\n",
        "    plt.axis('off')\n",
        "    im = plt.imshow(image_list[0])\n",
        " \n",
        "    def animate(k):\n",
        "        im.set_array(image_list[k])\n",
        "        return im,\n",
        "    ani = animation.FuncAnimation(fig, animate, frames=len(image_list), blit=True)\n",
        "    return ani\n",
        " \n",
        "def plot_annotation_strip(annotation_sequence, start_frame = 0, stop_frame = 100, title=\"Behavior Labels\"):\n",
        "  # Plot annotations as a annotation strip.\n",
        " \n",
        "  # Map annotations to a number.\n",
        "  annotation_num = []\n",
        "  for item in annotation_sequence[start_frame:stop_frame]:\n",
        "    annotation_num.append(class_to_number[item])\n",
        " \n",
        "  all_classes = list(set(annotation_sequence[start_frame:stop_frame]))\n",
        " \n",
        "  cmap = colors.ListedColormap(['white', 'red'])\n",
        "  bounds=[-0.5,0.5,1.5]\n",
        "  norm = colors.BoundaryNorm(bounds, cmap.N)\n",
        " \n",
        "  height = 200\n",
        "  arr_to_plot = np.repeat(np.array(annotation_num)[:,np.newaxis].transpose(),\n",
        "                                                  height, axis = 0)\n",
        "  \n",
        "  fig, ax = plt.subplots(figsize = (16, 3))\n",
        "  ax.imshow(arr_to_plot, interpolation = 'none',cmap=cmap, norm=norm)\n",
        " \n",
        "  ax.set_yticks([])\n",
        "  ax.set_xlabel('Frame Number')\n",
        "  plt.title(title)\n",
        " \n",
        "  import matplotlib.patches as mpatches\n",
        " \n",
        "  legend_patches = []\n",
        "  for item in all_classes:\n",
        "    legend_patches.append(mpatches.Patch(color=class_to_color[item], label=item))\n",
        " \n",
        "  plt.legend(handles=legend_patches,loc='center left', bbox_to_anchor=(1, 0.5))\n",
        " \n",
        "  plt.tight_layout()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p7WPezuV86QA"
      },
      "source": [
        "# Visualize the mouse movementsğŸ¥\n",
        "\n",
        "Sample visualization for plotting pose gifs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KSUZW-9J53kI"
      },
      "source": [
        "keypoint_sequence = single_sequence['keypoints']\n",
        "annotation_sequence = single_sequence['annotations']\n",
        "\n",
        "ani = animate_pose_sequence(sequence_key,\n",
        "                            keypoint_sequence, \n",
        "                            start_frame = 3000,\n",
        "                            stop_frame = 3100,\n",
        "                            annotation_sequence = annotation_sequence)\n",
        "\n",
        "# Display the animaion on colab\n",
        "ani"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_jhj4BtOkjM5"
      },
      "source": [
        "### Showing a section of the validation data (Index needs to be selected for a full video)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1u28cZOL8G29"
      },
      "source": [
        "annotation_sequence = single_sequence['annotations']\n",
        "text_sequence = num_to_text(annotation_sequence)\n",
        " \n",
        "plot_annotation_strip(\n",
        "    text_sequence,\n",
        "    start_frame=0,\n",
        "    stop_frame=len(annotation_sequence) + 1000\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rOs2KLHe9Ip1"
      },
      "source": [
        "# Basic EDA ğŸ¤“\n",
        "There are 7 new behaviors in task3, each has different frequency of occurence per video.\n",
        "\n",
        "Each sequence has different amounts of each behavior, here we get the percentage of frames of each behavior in each sequence. We can use this to split the dataset for validation in a stratified way."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uOm1Vtz4GDwh"
      },
      "source": [
        "# Function for showing dataframes nicely on jupyter\n",
        "from IPython.display import display, HTML\n",
        "def pretty_print_dataframe(df):\n",
        "  display(HTML(df.to_html()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JoqaPWYM9gdi"
      },
      "source": [
        "def get_behavior_percentage_frames(behavior_ds): \n",
        "  vocabulary = behavior_ds['vocabulary']\n",
        "  def get_percentage(sequence_key):\n",
        "    anno_seq = behavior_ds['sequences'][sequence_key]['annotations']\n",
        "    counts = {k: np.mean(np.array(anno_seq) == v) for k,v in vocabulary.items()}\n",
        "    return counts\n",
        "\n",
        "  anno_percentages = {k: get_percentage(k) for k in behavior_ds['sequences']}\n",
        "  anno_perc_df = pd.DataFrame(anno_percentages).T\n",
        "  return anno_perc_df\n",
        "\n",
        "print(\"Percentage of frames in every sequence for every class\")\n",
        "for behavior in train:\n",
        "  pretty_print_dataframe( get_behavior_percentage_frames(train[behavior]) )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ag4g-KT6TOPP"
      },
      "source": [
        "percentages = []\n",
        "for behavior in sorted(list(train.keys())):\n",
        "  beh_sequences = train[behavior]\n",
        "  all_annotations = []\n",
        "  for sk in beh_sequences['sequences']:\n",
        "    anno = beh_sequences['sequences'][sk]['annotations']\n",
        "    all_annotations.extend(list(anno))\n",
        "  percentages.append(np.mean(np.array(all_annotations) == 1))\n",
        "pd.DataFrame({\"Behavior\": sorted(list(train.keys())),\n",
        "              \"Percentage Frames\": percentages})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SCDiH6VCZ_EB"
      },
      "source": [
        "# Training The Model ğŸ‹ï¸â€â™‚ï¸\n",
        "\n",
        "The given MABe dataset contain many sequences of time series data, each frame has its own behavior label. Training on just a single frame does not give good results due to less information. \n",
        "\n",
        "So here past and future frames are also added to each input. But also all the frames are not concatenated as as the boundaries of the past and future frames need to stay separate for each video.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EHNBIrZSfMcn"
      },
      "source": [
        "## Seeding helper\n",
        "Its good practice to seed before every run, that way its easily reproduced."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r4rNTUuFaHmo"
      },
      "source": [
        "def seed_everything(seed):\n",
        "  np.random.seed(seed)\n",
        "  os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "  tf.random.set_seed(seed)\n",
        "\n",
        "seed=2021\n",
        "seed_everything(seed)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2cbXzIDFaA5o"
      },
      "source": [
        "## Generator ğŸ”Œ\n",
        "\n",
        "The generator is used to take input winodws from each sequence after randomly sampling frames. \n",
        "\n",
        "It also provides code for augmentations\n",
        "1.   Random rotation\n",
        "2.   Random translate\n",
        "\n",
        "ğŸš§ Note that these augmentations are applied in the same across all frames in a selected window, e.g - Random rotation by 10 degrees will rotate all frames in the input window by the same angle."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lAPk-wgqaETQ"
      },
      "source": [
        "class MABe_Generator(keras.utils.Sequence):\n",
        "    def __init__(self, pose_dict, \n",
        "                 batch_size, dim, \n",
        "                 use_conv, num_classes, augment=False,\n",
        "                 class_to_number=None,\n",
        "                 past_frames=0, future_frames=0, \n",
        "                 frame_gap=1, shuffle=False,\n",
        "                 mode='fit'):\n",
        "        self.batch_size = batch_size\n",
        "        self.video_keys = list(pose_dict.keys())\n",
        "        self.dim = dim\n",
        "        self.use_conv = use_conv\n",
        "        self.past_frames = past_frames\n",
        "        self.future_frames = future_frames\n",
        "        self.frame_gap = frame_gap\n",
        "        self.shuffle = shuffle\n",
        "        self.num_classes=num_classes\n",
        "        self.augment = augment\n",
        "        self.mode = mode\n",
        "\n",
        "        self.class_to_number = class_to_number\n",
        "\n",
        "        self.video_indexes = []\n",
        "        self.frame_indexes = []\n",
        "        self.X = {}\n",
        "        if self.mode == 'fit':\n",
        "          self.y = []\n",
        "        self.pad = self.past_frames * self.frame_gap\n",
        "        future_pad = self.future_frames * self.frame_gap\n",
        "        pad_width = (self.pad, future_pad), (0, 0), (0, 0), (0, 0)\n",
        "        self.seq_lengths = {}\n",
        "        for vc, key in enumerate(self.video_keys):\n",
        "          if self.mode == 'fit':\n",
        "            anno = pose_dict[key]['annotations']\n",
        "            self.y.extend(anno)\n",
        "          nframes = len(pose_dict[key]['keypoints'])\n",
        "          self.video_indexes.extend([vc for _ in range(nframes)])\n",
        "          self.frame_indexes.extend(range(nframes))\n",
        "          self.X[key] = np.pad(pose_dict[key]['keypoints'], pad_width)\n",
        "          self.seq_lengths[key] = nframes\n",
        "        \n",
        "        if self.mode == 'fit':\n",
        "          self.y = np.array(self.y)\n",
        "        \n",
        "        self.X_dtype = self.X[key].dtype\n",
        "\n",
        "        self.indexes = list(range(len(self.frame_indexes)))\n",
        "\n",
        "        if self.mode == 'predict':\n",
        "          extra_predicts = -len(self.indexes) % self.batch_size # So that last part is not missed\n",
        "          self.indexes.extend(self.indexes[:extra_predicts])\n",
        "          self.indexes = np.array(self.indexes)\n",
        "        \n",
        "        self.on_epoch_end()\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.indexes) // self.batch_size\n",
        "\n",
        "    def augment_fn(self, x):\n",
        "      # Rotate\n",
        "      angle = (np.random.rand()-0.5) * (np.pi * 2)\n",
        "      c, s = np.cos(angle), np.sin(angle)\n",
        "      rot = np.array([[c, -s], [s, c]])\n",
        "      x = np.dot(x, rot)\n",
        "\n",
        "      # Shift - All get shifted together\n",
        "      shift = (np.random.rand(2)-0.5) * 2 * 0.25\n",
        "      x = x + shift\n",
        "      return x\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        bs = self.batch_size\n",
        "        indexes = self.indexes[index*bs:(index+1)*bs]\n",
        "        X = np.empty((bs, *self.dim), self.X_dtype)\n",
        "        if self.mode == 'predict':\n",
        "          vkey_fi_list = []\n",
        "        for bi, idx in enumerate(indexes):\n",
        "          vkey = self.video_keys[self.video_indexes[idx]]\n",
        "          fi = self.frame_indexes[idx]\n",
        "          if self.mode == 'predict':\n",
        "            vkey_fi_list.append((vkey, fi))\n",
        "          fi = fi + self.pad\n",
        "          start = fi - self.past_frames*self.frame_gap\n",
        "          stop = fi + (self.future_frames + 1)*self.frame_gap\n",
        "          assert start >= 0\n",
        "\n",
        "          Xi = self.X[vkey][start:stop:self.frame_gap].copy()\n",
        "          \n",
        "          if self.augment:\n",
        "            Xi = self.augment_fn(Xi)\n",
        "          X[bi] = np.reshape(Xi, self.dim)\n",
        "          \n",
        "\n",
        "        if self.mode == 'fit':\n",
        "          y_vals = self.y[indexes]\n",
        "          # Converting to one hot because F1 callback needs one hot\n",
        "          y = np.zeros( (bs,self.num_classes), np.float32)\n",
        "          y[np.arange(bs), y_vals] = 1\n",
        "          return X, y\n",
        "\n",
        "        elif self.mode == 'predict':\n",
        "          return X, vkey_fi_list\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        if self.shuffle == True:\n",
        "            np.random.shuffle(self.indexes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ZZKIBIXfU1X"
      },
      "source": [
        "## Trainer ğŸ‹ï¸\n",
        "\n",
        "The trainer class implements a unified interface for using the datagenerator.\n",
        "\n",
        "It supports fully connected or 1D convolutional networks, as well as other hyperparameters for the model and the generator."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NYw6y0peZ-ch"
      },
      "source": [
        "class Trainer:\n",
        "  def __init__(self, *,\n",
        "               train_data,\n",
        "               val_data,\n",
        "               test_data,\n",
        "               feature_dim, \n",
        "               batch_size, \n",
        "               num_classes,\n",
        "               augment=False,\n",
        "               class_to_number=None,\n",
        "               past_frames=0, \n",
        "               future_frames=0,\n",
        "               frame_gap=1, \n",
        "               use_conv=False):\n",
        "    flat_dim = np.prod(feature_dim)\n",
        "    if use_conv:\n",
        "      input_dim = ((past_frames + future_frames + 1), flat_dim,)\n",
        "    else:\n",
        "      input_dim = (flat_dim * (past_frames + future_frames + 1),)\n",
        "\n",
        "    self.input_dim = input_dim\n",
        "    self.use_conv=use_conv\n",
        "    self.num_classes=num_classes\n",
        "\n",
        "    c2n = {'other': 0,'investigation': 1,\n",
        "                'attack' : 2, 'mount' : 3}\n",
        "    self.class_to_number = class_to_number or c2n\n",
        "\n",
        "    self.train_generator = MABe_Generator(train_data, \n",
        "                                      batch_size=batch_size, \n",
        "                                      dim=input_dim,\n",
        "                                      num_classes=num_classes, \n",
        "                                      past_frames=past_frames, \n",
        "                                      future_frames=future_frames,\n",
        "                                      class_to_number=self.class_to_number,\n",
        "                                      use_conv=use_conv,\n",
        "                                      frame_gap=frame_gap,\n",
        "                                      augment=augment,\n",
        "                                      shuffle=True,\n",
        "                                      mode='fit')\n",
        "\n",
        "    self.val_generator = MABe_Generator(val_data, \n",
        "                                        batch_size=batch_size, \n",
        "                                        dim=input_dim, \n",
        "                                        num_classes=num_classes, \n",
        "                                        past_frames=past_frames,\n",
        "                                        future_frames=future_frames,\n",
        "                                        use_conv=use_conv,\n",
        "                                        class_to_number=self.class_to_number,\n",
        "                                        frame_gap=frame_gap,\n",
        "                                        augment=False,\n",
        "                                        shuffle=False,\n",
        "                                        mode='fit')\n",
        "    \n",
        "    self.test_generator = MABe_Generator(test_data, \n",
        "                                        batch_size=8192, \n",
        "                                        dim=input_dim, \n",
        "                                        num_classes=num_classes, \n",
        "                                        past_frames=past_frames,\n",
        "                                        future_frames=future_frames,\n",
        "                                        use_conv=use_conv,\n",
        "                                        class_to_number=self.class_to_number,\n",
        "                                        frame_gap=frame_gap,\n",
        "                                        augment=False,\n",
        "                                        shuffle=False,\n",
        "                                        mode='predict')\n",
        "  \n",
        "  def delete_model(self):\n",
        "    self.model = None\n",
        "  \n",
        "  def initialize_model(self, layer_channels=(512, 256), dropout_rate=0., \n",
        "                       learning_rate=1e-3, conv_size=5):\n",
        "\n",
        "    def add_dense_bn_activate(model, out_dim, activation='relu', drop=0.):\n",
        "      model.add(layers.Dense(out_dim))\n",
        "      model.add(layers.BatchNormalization())\n",
        "      model.add(layers.Activation('relu'))\n",
        "      if drop > 0:\n",
        "        model.add(layers.Dropout(rate=drop))\n",
        "      return model\n",
        "    \n",
        "    def add_conv_bn_activate(model, out_dim, activation='relu', conv_size=3, drop=0.):\n",
        "      model.add(layers.Conv1D(out_dim, conv_size))\n",
        "      model.add(layers.BatchNormalization())\n",
        "      model.add(layers.Activation('relu'))\n",
        "      model.add(layers.MaxPooling1D(2, 2))\n",
        "      if drop > 0:\n",
        "        model.add(layers.Dropout(rate=drop))\n",
        "      return model\n",
        "\n",
        "    model = Sequential()\n",
        "    model.add(layers.Input(self.input_dim))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    for ch in layer_channels:\n",
        "      if self.use_conv:\n",
        "        model = add_conv_bn_activate(model, ch, conv_size=conv_size,\n",
        "                                     drop=dropout_rate)\n",
        "      else:\n",
        "        model = add_dense_bn_activate(model, ch, drop=dropout_rate)\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dense(self.num_classes, activation='softmax'))\n",
        "\n",
        "    metrics = [tfa.metrics.F1Score(num_classes=self.num_classes)]\n",
        "    optimizer = keras.optimizers.Adam(lr=learning_rate)\n",
        "    model.compile(loss='categorical_crossentropy', \n",
        "                  optimizer=optimizer,\n",
        "                  metrics=metrics)\n",
        "\n",
        "    self.model = model\n",
        "\n",
        "  def _set_model(self, model):\n",
        "      \"\"\" Set an external, provide initialized and compiled keras model \"\"\"\n",
        "      self.model = model\n",
        "\n",
        "  def train(self, epochs=20, class_weight=None):\n",
        "    if self.model is None:\n",
        "      print(\"Please Call trainer.initialize_model first\")\n",
        "      return\n",
        "    self.model.fit(self.train_generator,\n",
        "          validation_data=self.val_generator,\n",
        "          epochs=epochs,\n",
        "          class_weight=class_weight)\n",
        "        \n",
        "  def get_validation_labels(self, on_test_set=False):\n",
        "    y_val = []\n",
        "    for _, y in self.val_generator:\n",
        "      y_val.extend(list(y))\n",
        "    y_val = np.argmax(np.array(y_val), axis=-1)\n",
        "    return y_val\n",
        "\n",
        "  def get_validation_predictions(self):\n",
        "    y_val_pred = self.model.predict(self.val_generator)\n",
        "    y_val_pred = np.argmax(y_val_pred, axis=-1)\n",
        "    return y_val_pred\n",
        "\n",
        "  def get_validation_metrics(self):\n",
        "    y_val = self.get_validation_labels()\n",
        "    y_val_pred = self.get_validation_predictions()\n",
        "\n",
        "    f1_scores = sklearn.metrics.f1_score(y_val, y_val_pred,average=None)\n",
        "    rec_scores = sklearn.metrics.precision_score(y_val, y_val_pred,average=None)\n",
        "    prec_scores = sklearn.metrics.recall_score(y_val, y_val_pred,average=None)\n",
        "    classes = list(self.class_to_number.keys())\n",
        "    metrics = pd.DataFrame({\"Class\": classes, \"F1\": f1_scores, \"Precision\": prec_scores, \"Recall\": rec_scores})\n",
        "    return metrics\n",
        "  \n",
        "  def get_test_predictions(self):\n",
        "    all_test_preds = {}\n",
        "    for vkey in self.test_generator.video_keys:\n",
        "      nframes = self.test_generator.seq_lengths[vkey]\n",
        "      all_test_preds[vkey] = np.zeros(nframes, dtype=np.int32)\n",
        "\n",
        "    for X, vkey_fi_list in tqdm(self.test_generator):\n",
        "      test_pred = self.model.predict(X)\n",
        "      test_pred = np.argmax(test_pred, axis=-1)\n",
        "\n",
        "      for p, (vkey, fi) in zip(test_pred, vkey_fi_list):\n",
        "        all_test_preds[vkey][fi] = p\n",
        "    return all_test_preds"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OYYrvXNTaVfU"
      },
      "source": [
        "## Preprocess\n",
        "\n",
        "We'll normalize the data based on the information that the frame size is 1024x570\n",
        "\n",
        "The original data is of shape (sequence length, mouse, x y coordinate, keypoint)\n",
        " = (length, 2, 2, 7)\n",
        "\n",
        " We'll swap the x y and the keypoint axis, which will help in rotation augmentation.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xYKbWFVcaSeW"
      },
      "source": [
        "def normalize_data(orig_pose_dictionary):\n",
        "  for key in orig_pose_dictionary:\n",
        "    X = orig_pose_dictionary[key]['keypoints']\n",
        "    X = X.transpose((0,1,3,2)) #last axis is x, y coordinates\n",
        "    X[..., 0] = X[..., 0]/1024\n",
        "    X[..., 1] = X[..., 1]/570\n",
        "    orig_pose_dictionary[key]['keypoints'] = X\n",
        "  return orig_pose_dictionary"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KWdrGN38fmQf"
      },
      "source": [
        "## Dataset split\n",
        "Since MABe has multiple sequences, it is sensible to split the dataset based on different sequences rather than randomly sampling frames, which may leak information.\n",
        "\n",
        "About half the sequences don't have \"attack\" behavior, hence we'll stratify based on whether \"attack\" behavior is present or absent.\n",
        "\n",
        "This function only does a single split, but you can also do multiple splits for cross validation.\n",
        "\n",
        "For Task 2 and 3 there are very few sequences, hence we split the sequences in half for validation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C7iuMRKKakls"
      },
      "source": [
        "def split_validation(orig_pose_dictionary, seed=2021, \n",
        "                       test_size=0.5, split_videos=False):\n",
        "  if split_videos:\n",
        "    pose_dictionary = {}\n",
        "    for key in orig_pose_dictionary:\n",
        "      key_pt1 = key + '_part1'\n",
        "      key_pt2 = key + '_part2'\n",
        "      anno_len = len(orig_pose_dictionary[key]['annotations'])\n",
        "      split_idx = anno_len//2\n",
        "      pose_dictionary[key_pt1] = {\n",
        "          'annotations': orig_pose_dictionary[key]['annotations'][:split_idx],\n",
        "          'keypoints': orig_pose_dictionary[key]['keypoints'][:split_idx]}\n",
        "      pose_dictionary[key_pt2] = {\n",
        "          'annotations': orig_pose_dictionary[key]['annotations'][split_idx:],\n",
        "          'keypoints': orig_pose_dictionary[key]['keypoints'][split_idx:]}\n",
        "  else:\n",
        "    pose_dictionary = orig_pose_dictionary\n",
        "  \n",
        "\n",
        "  all_anno = []\n",
        "  for key in pose_dictionary:\n",
        "    all_anno.extend(pose_dictionary[key]['annotations'])\n",
        "  keys = np.unique(all_anno)\n",
        "  def get_percentage(task_key):\n",
        "    anno_seq = pose_dictionary[task_key]['annotations']\n",
        "    counts = {k: np.mean(np.array(anno_seq) == k) for k in keys}\n",
        "    return counts\n",
        "\n",
        "  anno_percentages = {tk: get_percentage(tk) for tk in pose_dictionary}\n",
        "  anno_perc_df = pd.DataFrame(anno_percentages).T\n",
        "\n",
        "  rng_state = np.random.RandomState(seed)\n",
        "  try:\n",
        "    idx_train, idx_val = train_test_split(anno_perc_df.index,\n",
        "                                      stratify=anno_perc_df['attack'] > 0, \n",
        "                                      test_size=test_size,\n",
        "                                      random_state=rng_state)\n",
        "  except:\n",
        "    idx_train, idx_val = train_test_split(anno_perc_df.index,\n",
        "                                      test_size=test_size,\n",
        "                                      random_state=rng_state)\n",
        "    \n",
        "  train_data = {k : pose_dictionary[k] for k in idx_train}\n",
        "  val_data = {k : pose_dictionary[k] for k in idx_val}\n",
        "  return train_data, val_data, anno_perc_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xoa2_gY2PMbB"
      },
      "source": [
        "# Train function and inference\n",
        "\n",
        "This below function is specific for Task 3, it has a set of hyperparameters we found with some tuning. Though results can be improved with further tuning.\n",
        "\n",
        "* It trains a binary classifier for each new behavior class.\n",
        "\n",
        "* It has the option to use a pretrained model from Task1. \n",
        "\n",
        "* It also generates the submission dictionary after training is completed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cJaqWkXgamKv"
      },
      "source": [
        "def run_task3(results_dir, dataset, test_data, behavior, class_weight, pretrained_file=None):\n",
        "  HPARAMS = {}\n",
        "  val_size = HPARAMS[\"val_size\"] = 0.5\n",
        "  normalize = HPARAMS[\"normalize\"] = True\n",
        "  HPARAMS[\"seed\"] = seed\n",
        "  split_videos = HPARAMS[\"split_videos\"] = True\n",
        "\n",
        "  if normalize:\n",
        "    dataset = normalize_data(deepcopy(dataset))\n",
        "    test_data = normalize_data(deepcopy(test_data))\n",
        "\n",
        "  train_data, val_data, anno_perc_df = split_validation(dataset, \n",
        "                                                        seed=seed, \n",
        "                                                        test_size=val_size, \n",
        "                                                        split_videos=split_videos)                            \n",
        "  num_classes = len(anno_perc_df.keys())\n",
        "  feature_dim = HPARAMS[\"feature_dim\"] = (2,7,2)\n",
        "\n",
        "  # Generator parameters\n",
        "  past_frames = HPARAMS[\"past_frames\"] = 50\n",
        "  future_frames = HPARAMS[\"future_frames\"] = 50\n",
        "  frame_gap = HPARAMS[\"frame_gap\"] = 1\n",
        "  use_conv = HPARAMS[\"use_conv\"] = True\n",
        "  batch_size = HPARAMS[\"batch_size\"] = 128\n",
        "\n",
        "  # Model parameters\n",
        "  dropout_rate = HPARAMS[\"dropout_rate\"] = 0.5\n",
        "  learning_rate = HPARAMS[\"learning_rate\"] = 5e-5\n",
        "  layer_channels = HPARAMS[\"layer_channels\"] = (128, 64, 32)\n",
        "  conv_size = HPARAMS[\"conv_size\"] = 5\n",
        "  augment = HPARAMS[\"augment\"] = True\n",
        "  epochs = HPARAMS[\"epochs\"] = 20\n",
        "  class_to_number = HPARAMS['class_to_number'] = {\"other\": 0, behavior: 1}\n",
        "  HPARAMS['class_weight'] = class_weight\n",
        "\n",
        "  trainer = Trainer(train_data=train_data,\n",
        "                    val_data=val_data,\n",
        "                    test_data=test_data,\n",
        "                    feature_dim=feature_dim, \n",
        "                    batch_size=batch_size, \n",
        "                    num_classes=num_classes,\n",
        "                    augment=augment,\n",
        "                    class_to_number=class_to_number,\n",
        "                    past_frames=past_frames, \n",
        "                    future_frames=future_frames,\n",
        "                    frame_gap=frame_gap,\n",
        "                    use_conv=use_conv)\n",
        "\n",
        "  trainer.initialize_model(layer_channels=layer_channels,\n",
        "                          dropout_rate=dropout_rate,\n",
        "                          learning_rate=learning_rate,\n",
        "                          conv_size=conv_size)\n",
        "  \n",
        "  if pretrained_file and os.path.exists(pretrained_file):\n",
        "    HPARAMS['pretrained_file'] = pretrained_file\n",
        "    \n",
        "    # Load encoder weights Freeze all except top layer\n",
        "    pretrained_model = keras.models.load_model(pretrained_file)\n",
        "    for idx, layer in enumerate(pretrained_model.layers[:-1]):\n",
        "      trainer.model.layers[idx].set_weights(layer.get_weights())\n",
        "      if not isinstance(layer, layers.BatchNormalization):\n",
        "        trainer.model.layers[idx].trainable = False\n",
        "    \n",
        "    linear_probe_epochs = HPARAMS['linear_probe_epochs'] = 30\n",
        "    linear_probe_lr = HPARAMS['linear_probe_lr'] = 1e-3\n",
        "    trainer.model.optimizer.learning_rate.assign(linear_probe_lr)\n",
        "    trainer.train(epochs=linear_probe_epochs, class_weight=class_weight)\n",
        "\n",
        "    # Unfreeze layers\n",
        "    for idx, layer in enumerate(pretrained_model.layers[:-1]):\n",
        "      trainer.model.layers[idx].trainable = True\n",
        "    trainer.model.optimizer.learning_rate.assign(learning_rate)\n",
        "  \n",
        "  trainer.train(epochs=epochs, class_weight=class_weight)\n",
        "  trainer.model.save(f'{results_dir}/task3_{behavior}.h5')\n",
        "  np.save(f\"{results_dir}/task3_{behavior}_hparams\", HPARAMS)\n",
        "\n",
        "  val_metrics = trainer.get_validation_metrics()\n",
        "  test_results = trainer.get_test_predictions()\n",
        "\n",
        "  np.save(f\"{results_dir}/task3_{behavior}_test_results\", test_results) \n",
        "  val_metrics.to_csv(f\"{results_dir}/task3_{behavior}_metrics_val.csv\", index=False)\n",
        "  del trainer # clear ram as the test dataset is large\n",
        "  del dataset # clear ram as the test dataset is large\n",
        "  del test_data # clear ram as the test dataset is large\n",
        "  del train_data, val_data # clear ram as the test dataset is large\n",
        "  gc.collect() \n",
        "  return test_results"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6DuGiwudQKfY"
      },
      "source": [
        "# Class Weights for loss function\n",
        "\n",
        "* Since there is huge imbalance in each behavior class, increasing class weight of behaviors helps.\n",
        "\n",
        "* These are set based on the percentage of frames found in the EDA section.\n",
        "\n",
        "* There is not clear formula for this, but 1/(fraction of frames) is a good starting point and can be further tuned from there."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KvUripYfsEUA"
      },
      "source": [
        "class_weights_task3 = {\n",
        "    \"behavior-0\": {0: 1, 1: 20},\n",
        "    \"behavior-1\": {0: 1, 1: 50},\n",
        "    \"behavior-2\": {0: 1, 1: 5},\n",
        "    \"behavior-3\": {0: 1, 1: 3},\n",
        "    \"behavior-4\": {0: 1, 1: 100},\n",
        "    \"behavior-5\": {0: 1, 1: 20},\n",
        "    \"behavior-6\": {0: 1, 1: 10},\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sGKMV1qwQznl"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ThwamdXBsvud"
      },
      "source": [
        "results_dir = '.'\n",
        "# Need to take this file from task 1, also make sure all network params and generator parameters are same\n",
        "pretrained_file = \"/content/drive/MyDrive/aicrowd_mabe_models/task1_augmented.h5\" \n",
        "# pretrained_file = None # If you want to skip the pretrained model part - uncomment this\n",
        "submission = {}\n",
        "for behavior in train:\n",
        "  class_weight = class_weights_task3[behavior]\n",
        "  behavior_results= run_task3(results_dir, \n",
        "                              train[behavior]['sequences'],\n",
        "                              test['sequences'], \n",
        "                              behavior, \n",
        "                              class_weight, \n",
        "                              pretrained_file)\n",
        "  submission[behavior] = behavior_results\n",
        "  gc.collect() # clear RAM as the test dataset is large"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zZYfbeJIrNt9"
      },
      "source": [
        "# Validate the submission âœ…\n",
        "The submssion should follow these constraints:\n",
        "\n",
        "1.   It should be a dictionary\n",
        "2.   It should be have same keys as sample_submission\n",
        "3.   It should have dictionaries for all behaviors\n",
        "4.   The lengths of the arrays are same\n",
        "5.   All values are intergers\n",
        "\n",
        "You can use the helper function below to check these\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nl5FrGHcrLy4"
      },
      "source": [
        "def validate_submission(submission, sample_submission):\n",
        "    if not isinstance(submission, dict):\n",
        "        print(\"Submission should be dict\")\n",
        "        return False\n",
        "    \n",
        "    if not submission.keys() == sample_submission.keys():\n",
        "        print(\"Submission keys don't match\")\n",
        "        return False\n",
        "    for behavior in submission:\n",
        "      sb = submission[behavior]\n",
        "      ssb = sample_submission[behavior]\n",
        "      if not isinstance(sb, dict):\n",
        "        print(\"Submission should be dict\")\n",
        "        return False\n",
        "\n",
        "      if not sb.keys() == ssb.keys():\n",
        "        print(\"Submission keys don't match\")\n",
        "        return False\n",
        "      \n",
        "      for key in sb:\n",
        "        sv = sb[key]\n",
        "        ssv = ssb[key]\n",
        "        if not len(sv) == len(ssv):\n",
        "          print(f\"Submission lengths of {key} doesn't match\")\n",
        "          return False\n",
        "      \n",
        "      for key, sv in sb.items():\n",
        "        if not all(isinstance(x, (np.int32, np.int64, int)) for x in list(sv)):\n",
        "          print(f\"Submission of {key} is not all integers\")\n",
        "          return False\n",
        "    \n",
        "    print(\"All tests passed\")\n",
        "    return True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k_twyjQEyaUy"
      },
      "source": [
        "validate_submission(submission, sample_submission)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nPfKXGb1vTRd"
      },
      "source": [
        "## Save the prediction as `npy` ğŸ“¨"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1LkuPd5AvTRd"
      },
      "source": [
        "np.save(\"submission.npy\", submission)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aEZqmoHJJl4j"
      },
      "source": [
        "## Submit to AIcrowd ğŸš€"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yaUu2j8tCdZ1"
      },
      "source": [
        "!aicrowd submission create -c mabe-task-3-learning-new-behavior -f submission.npy"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}